# AI Job Market Analyzer â€“ Germany

This project analyzes the German AI/Data job market by extracting required skills from job postings and visualizing trends using an interactive Streamlit dashboard.

Built with:  
ğŸ **Python** | ğŸ” **NLP (RapidFuzz)** | ğŸ¨ **Streamlit** | ğŸ“¦ **Docker** | âš™ï¸ **CI/CD**

---

## ğŸš€ Features

### ğŸ” Job Postings ETL Pipeline
- Load job listings from CSV/JSON/API  
- Clean and normalize columns  
- Save processed results as Parquet  

### ğŸ§  Skill Extraction (NLP)
- Uses fuzzy matching (RapidFuzz)  
- Detects most common AI/Data skills  
- Fully configurable skills dictionary  

### ğŸ“ˆ Interactive Streamlit Dashboard
- Filter by location  
- Search by desired skill (Python, SQL, Dockerâ€¦)  
- Explore top skills in the job market  
- Direct links to job pages  

### ğŸ³ Docker Support
Fully containerized â€” run anywhere:
```bash
docker run -p 8501:8501 job-analyzer
```

### ğŸ”„ CI/CD (GitHub Actions)
- Automatic Docker image build  
- Future: Auto-deploy to HuggingFace Spaces  

---

## ğŸ—ï¸ Project Structure

```
job-market-analyzer/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py              # Streamlit dashboard
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw input data
â”‚   â””â”€â”€ processed/           # ETL output (.parquet)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl/                 # ETL pipeline scripts
â”‚   â”œâ”€â”€ nlp/                 # Skill extraction logic
â”‚   â””â”€â”€ viz/                 # Charts
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_etl_eda.ipynb     # ETL notebook
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Run Locally

### 1) Create and activate virtual environment
```bash
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Run the ETL notebook
Open and run:

```
notebooks/01_etl_eda.ipynb
```

This produces:

```
data/processed/jobs_with_skills.parquet
```

### 3) Start the Streamlit app
```bash
streamlit run app/main.py
```

---

## ğŸ³ Run with Docker

### 1) Build image
```bash
docker build -t job-analyzer .
```

### 2) Run container
```bash
docker run -p 8501:8501 job-analyzer
```

Open:

ğŸ‘‰ http://localhost:8501

---

## ğŸŒ Deployment (Coming)
Planned improvements:
- Deploy to **Hugging Face Spaces**
- Add **GitHub Actions CI/CD workflow**
- Auto-build and auto-deploy the dashboard

---

## âœ¨ Future Enhancements
- ML-based skill extraction using transformers  
- Trend forecasting model  
- Real-time scraping via API  
- Auto-updating dashboard (cron jobs)  

---

## ğŸ“¬ Contact
ğŸŒ GitHub: https://github.com/halfaaa

